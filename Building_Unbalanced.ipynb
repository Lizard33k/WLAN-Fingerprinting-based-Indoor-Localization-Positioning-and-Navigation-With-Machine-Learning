{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import csv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>WAP001</th>\n",
       "      <th>WAP002</th>\n",
       "      <th>WAP003</th>\n",
       "      <th>WAP004</th>\n",
       "      <th>WAP005</th>\n",
       "      <th>WAP006</th>\n",
       "      <th>WAP007</th>\n",
       "      <th>WAP008</th>\n",
       "      <th>WAP009</th>\n",
       "      <th>WAP010</th>\n",
       "      <th>...</th>\n",
       "      <th>LONGITUDE</th>\n",
       "      <th>LATITUDE</th>\n",
       "      <th>FLOOR</th>\n",
       "      <th>BUILDINGID</th>\n",
       "      <th>SPACEID</th>\n",
       "      <th>RELATIVEPOSITION</th>\n",
       "      <th>USERID</th>\n",
       "      <th>PHONEID</th>\n",
       "      <th>TIMESTAMP</th>\n",
       "      <th>New</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>...</td>\n",
       "      <td>-7541.2643</td>\n",
       "      <td>4864920.778</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>106</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>23</td>\n",
       "      <td>1371713733</td>\n",
       "      <td>721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>...</td>\n",
       "      <td>-7536.6212</td>\n",
       "      <td>4864934.225</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>106</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>23</td>\n",
       "      <td>1371713691</td>\n",
       "      <td>721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>-97</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>...</td>\n",
       "      <td>-7519.1524</td>\n",
       "      <td>4864949.532</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>103</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>23</td>\n",
       "      <td>1371714095</td>\n",
       "      <td>721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>...</td>\n",
       "      <td>-7524.5704</td>\n",
       "      <td>4864934.093</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>102</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>23</td>\n",
       "      <td>1371713807</td>\n",
       "      <td>721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>...</td>\n",
       "      <td>-7632.1436</td>\n",
       "      <td>4864982.217</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>122</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>13</td>\n",
       "      <td>1369909710</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19932</th>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>...</td>\n",
       "      <td>-7485.4686</td>\n",
       "      <td>4864874.716</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>18</td>\n",
       "      <td>10</td>\n",
       "      <td>1371710683</td>\n",
       "      <td>3646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19933</th>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>...</td>\n",
       "      <td>-7390.6206</td>\n",
       "      <td>4864836.056</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>140</td>\n",
       "      <td>2</td>\n",
       "      <td>18</td>\n",
       "      <td>10</td>\n",
       "      <td>1371710402</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19934</th>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>...</td>\n",
       "      <td>-7516.8415</td>\n",
       "      <td>4864889.291</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>18</td>\n",
       "      <td>10</td>\n",
       "      <td>1371710921</td>\n",
       "      <td>3646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19935</th>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>...</td>\n",
       "      <td>-7537.3219</td>\n",
       "      <td>4864895.776</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>113</td>\n",
       "      <td>2</td>\n",
       "      <td>18</td>\n",
       "      <td>10</td>\n",
       "      <td>1371711049</td>\n",
       "      <td>3646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19936</th>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>...</td>\n",
       "      <td>-7536.1658</td>\n",
       "      <td>4864897.859</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>112</td>\n",
       "      <td>2</td>\n",
       "      <td>18</td>\n",
       "      <td>10</td>\n",
       "      <td>1371711025</td>\n",
       "      <td>3646</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>19937 rows Ã— 530 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       WAP001  WAP002  WAP003  WAP004  WAP005  WAP006  WAP007  WAP008  WAP009  \\\n",
       "0         100     100     100     100     100     100     100     100     100   \n",
       "1         100     100     100     100     100     100     100     100     100   \n",
       "2         100     100     100     100     100     100     100     -97     100   \n",
       "3         100     100     100     100     100     100     100     100     100   \n",
       "4         100     100     100     100     100     100     100     100     100   \n",
       "...       ...     ...     ...     ...     ...     ...     ...     ...     ...   \n",
       "19932     100     100     100     100     100     100     100     100     100   \n",
       "19933     100     100     100     100     100     100     100     100     100   \n",
       "19934     100     100     100     100     100     100     100     100     100   \n",
       "19935     100     100     100     100     100     100     100     100     100   \n",
       "19936     100     100     100     100     100     100     100     100     100   \n",
       "\n",
       "       WAP010  ...  LONGITUDE     LATITUDE  FLOOR  BUILDINGID  SPACEID  \\\n",
       "0         100  ... -7541.2643  4864920.778      2           1      106   \n",
       "1         100  ... -7536.6212  4864934.225      2           1      106   \n",
       "2         100  ... -7519.1524  4864949.532      2           1      103   \n",
       "3         100  ... -7524.5704  4864934.093      2           1      102   \n",
       "4         100  ... -7632.1436  4864982.217      0           0      122   \n",
       "...       ...  ...        ...          ...    ...         ...      ...   \n",
       "19932     100  ... -7485.4686  4864874.716      3           1        1   \n",
       "19933     100  ... -7390.6206  4864836.056      1           2      140   \n",
       "19934     100  ... -7516.8415  4864889.291      3           1       13   \n",
       "19935     100  ... -7537.3219  4864895.776      3           1      113   \n",
       "19936     100  ... -7536.1658  4864897.859      3           1      112   \n",
       "\n",
       "       RELATIVEPOSITION  USERID  PHONEID   TIMESTAMP   New  \n",
       "0                     2       2       23  1371713733   721  \n",
       "1                     2       2       23  1371713691   721  \n",
       "2                     2       2       23  1371714095   721  \n",
       "3                     2       2       23  1371713807   721  \n",
       "4                     2      11       13  1369909710     0  \n",
       "...                 ...     ...      ...         ...   ...  \n",
       "19932                 2      18       10  1371710683  3646  \n",
       "19933                 2      18       10  1371710402    47  \n",
       "19934                 2      18       10  1371710921  3646  \n",
       "19935                 2      18       10  1371711049  3646  \n",
       "19936                 2      18       10  1371711025  3646  \n",
       "\n",
       "[19937 rows x 530 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds=pd.read_csv(\"TrainingData.csv\")\n",
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>WAP001</th>\n",
       "      <th>WAP002</th>\n",
       "      <th>WAP003</th>\n",
       "      <th>WAP004</th>\n",
       "      <th>WAP005</th>\n",
       "      <th>WAP006</th>\n",
       "      <th>WAP007</th>\n",
       "      <th>WAP008</th>\n",
       "      <th>WAP009</th>\n",
       "      <th>WAP010</th>\n",
       "      <th>...</th>\n",
       "      <th>WAP514</th>\n",
       "      <th>WAP515</th>\n",
       "      <th>WAP516</th>\n",
       "      <th>WAP517</th>\n",
       "      <th>WAP518</th>\n",
       "      <th>WAP519</th>\n",
       "      <th>WAP520</th>\n",
       "      <th>LONGITUDE</th>\n",
       "      <th>LATITUDE</th>\n",
       "      <th>New</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>...</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>-7541.2643</td>\n",
       "      <td>4864920.778</td>\n",
       "      <td>721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>...</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>-7536.6212</td>\n",
       "      <td>4864934.225</td>\n",
       "      <td>721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>-97</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>...</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>-7519.1524</td>\n",
       "      <td>4864949.532</td>\n",
       "      <td>721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>...</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>-7524.5704</td>\n",
       "      <td>4864934.093</td>\n",
       "      <td>721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>...</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>-7632.1436</td>\n",
       "      <td>4864982.217</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19932</th>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>...</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>-7485.4686</td>\n",
       "      <td>4864874.716</td>\n",
       "      <td>3646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19933</th>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>...</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>-7390.6206</td>\n",
       "      <td>4864836.056</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19934</th>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>...</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>-7516.8415</td>\n",
       "      <td>4864889.291</td>\n",
       "      <td>3646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19935</th>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>...</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>-7537.3219</td>\n",
       "      <td>4864895.776</td>\n",
       "      <td>3646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19936</th>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>...</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>-7536.1658</td>\n",
       "      <td>4864897.859</td>\n",
       "      <td>3646</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>19937 rows Ã— 523 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       WAP001  WAP002  WAP003  WAP004  WAP005  WAP006  WAP007  WAP008  WAP009  \\\n",
       "0         100     100     100     100     100     100     100     100     100   \n",
       "1         100     100     100     100     100     100     100     100     100   \n",
       "2         100     100     100     100     100     100     100     -97     100   \n",
       "3         100     100     100     100     100     100     100     100     100   \n",
       "4         100     100     100     100     100     100     100     100     100   \n",
       "...       ...     ...     ...     ...     ...     ...     ...     ...     ...   \n",
       "19932     100     100     100     100     100     100     100     100     100   \n",
       "19933     100     100     100     100     100     100     100     100     100   \n",
       "19934     100     100     100     100     100     100     100     100     100   \n",
       "19935     100     100     100     100     100     100     100     100     100   \n",
       "19936     100     100     100     100     100     100     100     100     100   \n",
       "\n",
       "       WAP010  ...  WAP514  WAP515  WAP516  WAP517  WAP518  WAP519  WAP520  \\\n",
       "0         100  ...     100     100     100     100     100     100     100   \n",
       "1         100  ...     100     100     100     100     100     100     100   \n",
       "2         100  ...     100     100     100     100     100     100     100   \n",
       "3         100  ...     100     100     100     100     100     100     100   \n",
       "4         100  ...     100     100     100     100     100     100     100   \n",
       "...       ...  ...     ...     ...     ...     ...     ...     ...     ...   \n",
       "19932     100  ...     100     100     100     100     100     100     100   \n",
       "19933     100  ...     100     100     100     100     100     100     100   \n",
       "19934     100  ...     100     100     100     100     100     100     100   \n",
       "19935     100  ...     100     100     100     100     100     100     100   \n",
       "19936     100  ...     100     100     100     100     100     100     100   \n",
       "\n",
       "       LONGITUDE     LATITUDE   New  \n",
       "0     -7541.2643  4864920.778   721  \n",
       "1     -7536.6212  4864934.225   721  \n",
       "2     -7519.1524  4864949.532   721  \n",
       "3     -7524.5704  4864934.093   721  \n",
       "4     -7632.1436  4864982.217     0  \n",
       "...          ...          ...   ...  \n",
       "19932 -7485.4686  4864874.716  3646  \n",
       "19933 -7390.6206  4864836.056    47  \n",
       "19934 -7516.8415  4864889.291  3646  \n",
       "19935 -7537.3219  4864895.776  3646  \n",
       "19936 -7536.1658  4864897.859  3646  \n",
       "\n",
       "[19937 rows x 523 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X=ds.copy()\n",
    "y=X.BUILDINGID\n",
    "col=[\"USERID\",\"RELATIVEPOSITION\",\"PHONEID\",\"TIMESTAMP\",\"FLOOR\",'SPACEID','BUILDINGID']\n",
    "X.drop(col, axis=1, inplace=True)\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3    5048\n",
       "1    5002\n",
       "2    4416\n",
       "0    4369\n",
       "4    1102\n",
       "Name: FLOOR, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds['FLOOR'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.        , 1.        , 0.        , ..., 0.38429357, 0.64601411,\n",
       "        0.06257594],\n",
       "       [1.        , 1.        , 0.        , ..., 0.39618312, 0.69564447,\n",
       "        0.06257594],\n",
       "       [1.        , 1.        , 0.        , ..., 0.44091534, 0.75213975,\n",
       "        0.06257594],\n",
       "       ...,\n",
       "       [1.        , 1.        , 0.        , ..., 0.44683285, 0.52980147,\n",
       "        0.31643812],\n",
       "       [1.        , 1.        , 0.        , ..., 0.39438885, 0.55373639,\n",
       "        0.31643812],\n",
       "       [1.        , 1.        , 0.        , ..., 0.39734926, 0.56142436,\n",
       "        0.31643812]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "sc = MinMaxScaler()\n",
    "X= sc.fit_transform(X)\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.        , 1.        , 1.        , ..., 0.38429357, 0.64601411,\n",
       "        0.06257594],\n",
       "       [1.        , 1.        , 1.        , ..., 0.39618312, 0.69564447,\n",
       "        0.06257594],\n",
       "       [1.        , 0.00505051, 1.        , ..., 0.44091534, 0.75213975,\n",
       "        0.06257594],\n",
       "       ...,\n",
       "       [1.        , 1.        , 1.        , ..., 0.44683285, 0.52980147,\n",
       "        0.31643812],\n",
       "       [1.        , 1.        , 1.        , ..., 0.39438885, 0.55373639,\n",
       "        0.31643812],\n",
       "       [1.        , 1.        , 1.        , ..., 0.39734926, 0.56142436,\n",
       "        0.31643812]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "X = SelectKBest(chi2, k=200).fit_transform(X,y)\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "kf = KFold(n_splits=4, random_state=None, shuffle=True)\n",
    "kf.get_n_splits(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1249    0    0]\n",
      " [   2 1303    0]\n",
      " [   0    4 2427]]\n",
      "[[1321    0    0]\n",
      " [   0 1326    0]\n",
      " [   0    4 2333]]\n",
      "[[1309    0    0]\n",
      " [   3 1276    0]\n",
      " [   0    5 2391]]\n",
      "[[1370    0    0]\n",
      " [   0 1286    0]\n",
      " [   0    0 2328]]\n",
      "ROC_Score :  0.9998627013696608\n",
      "Sensitivity :  1.0\n",
      "Scores for RF : [0.9987963891675025, 0.9991974317817014, 0.9983948635634029, 1.0]\n",
      "Mean Test Score for RF: 0.9990971711281517\n",
      "Scores for RFt : [0.999665596575709, 0.9998662475757373, 0.999799371363606, 1.0]\n",
      "Mean Training Score for RFt: 0.999832803878763\n",
      "Precision Scores for RF : [0.9984469450708242, 0.9989974937343359, 0.9979367380032115, 1.0]\n",
      "Mean Precision Score for RF: 0.9988452942020929\n",
      "Recall Scores for RF : [0.998940673180024, 0.9994294679788903, 0.998522535387143, 1.0]\n",
      "Mean Recall Score for RF: 0.9992231691365143\n",
      "f1 Scores for RF : [0.9986931751796977, 0.9992124816181214, 0.9982286343980387, 1.0]\n",
      "Mean f1 Score for RF: 0.9990335727989644\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(3)\n",
    "#RF\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "RF=RandomForestClassifier(n_estimators=2)\n",
    "rf_score  =[]\n",
    "rft_score=[]\n",
    "rf_pre=[]\n",
    "rf_rec=[]\n",
    "rf_f1=[]\n",
    "lr_sen=[]\n",
    "lr_roc=[]\n",
    "for train_index, test_index in kf.split(X):\n",
    "    X_train, y_train = X[train_index], y[train_index]\n",
    "    X_test, y_test   = X[test_index], y[test_index]\n",
    "    RF.fit(X_train,y_train)\n",
    "    pred_rf=RF.predict(X_test)\n",
    "    accur_rf=accuracy_score(y_test,pred_rf)\n",
    "    pred1_rf=RF.predict(X_train)\n",
    "    accur1_rf=accuracy_score(y_train,pred1_rf)\n",
    "    rf_score.append(accur_rf)\n",
    "    rft_score.append(accur1_rf)\n",
    "    y_pred_proba = RF.predict_proba(X_test)\n",
    "    prec_rf=precision_score(y_test,pred_rf,average='macro')\n",
    "    rf_pre.append(prec_rf)\n",
    "    rec_rf=recall_score(y_test,pred_rf,average='macro')\n",
    "    rf_rec.append(rec_rf)\n",
    "    f1_rf=f1_score(y_test,pred_rf,average='macro')\n",
    "    rf_f1.append(f1_rf)\n",
    "    rf_confusion=confusion_matrix(y_test,pred_rf)\n",
    "    print(rf_confusion)\n",
    "    sensitivity = rf_confusion[0,0]/(rf_confusion[0,0]+rf_confusion[0,1])\n",
    "    ROC_score=roc_auc_score(y_test,y_pred_proba , average='weighted', multi_class='ovr')\n",
    "    lr_sen.append(sensitivity)\n",
    "    lr_roc.append(ROC_score)\n",
    "print('ROC_Score : ',np.mean (lr_roc))\n",
    "print('Sensitivity : ',np.mean (lr_sen))\n",
    "print('Scores for RF :',rf_score)\n",
    "print('Mean Test Score for RF:',np.mean(rf_score))\n",
    "print('Scores for RFt :',rft_score)\n",
    "print('Mean Training Score for RFt:',np.mean(rft_score))\n",
    "print('Precision Scores for RF :',rf_pre)\n",
    "print('Mean Precision Score for RF:',np.mean(rf_pre))\n",
    "print('Recall Scores for RF :',rf_rec)\n",
    "print('Mean Recall Score for RF:',np.mean(rf_rec))\n",
    "print('f1 Scores for RF :',rf_f1)\n",
    "print('Mean f1 Score for RF:',np.mean(rf_f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1249    0    0]\n",
      " [   0 1304    1]\n",
      " [   0    3 2428]]\n",
      "[[1321    0    0]\n",
      " [   0 1325    1]\n",
      " [   0    0 2337]]\n",
      "[[1308    1    0]\n",
      " [   0 1277    2]\n",
      " [   0    0 2396]]\n",
      "[[1368    2    0]\n",
      " [   0 1285    1]\n",
      " [   0    3 2325]]\n",
      "ROC_Score :  0.9998490363026873\n",
      "Sensitivity :  0.9994440510112472\n",
      "Scores for RF : [0.999197592778335, 0.9997993579454254, 0.9993980738362761, 0.9987961476725522]\n",
      "Mean Test Score for RF: 0.9992977930581473\n",
      "Scores for RFt : [0.9995987158908507, 0.9995318665150806, 0.9996656189393432, 0.9997324951514747]\n",
      "Mean Training Score for RFt: 0.9996321741241874\n",
      "Precision Scores for RF : [0.9990976583741324, 0.9998574280011406, 0.9994611663431924, 0.9985647027979407]\n",
      "Mean Precision Score for RF: 0.9992452388791015\n",
      "Recall Scores for RF : [0.9993332188058354, 0.9997486173956762, 0.9992241121340143, 0.9988246270716384]\n",
      "Mean Recall Score for RF: 0.9992826438517911\n",
      "f1 Scores for RF : [0.9992151870547877, 0.9998029600372779, 0.9993424816727116, 0.9986936238478953]\n",
      "Mean f1 Score for RF: 0.9992635631531681\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(3)\n",
    "#KNN\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "RF=KNeighborsClassifier()\n",
    "rf_score  =[]\n",
    "rft_score=[]\n",
    "rf_pre=[]\n",
    "rf_rec=[]\n",
    "rf_f1=[]\n",
    "lr_sen=[]\n",
    "lr_roc=[]\n",
    "for train_index, test_index in kf.split(X):\n",
    "    X_train, y_train = X[train_index], y[train_index]\n",
    "    X_test, y_test   = X[test_index], y[test_index]\n",
    "    RF.fit(X_train,y_train)\n",
    "    pred_rf=RF.predict(X_test)\n",
    "    accur_rf=accuracy_score(y_test,pred_rf)\n",
    "    pred1_rf=RF.predict(X_train)\n",
    "    accur1_rf=accuracy_score(y_train,pred1_rf)\n",
    "    rf_score.append(accur_rf)\n",
    "    rft_score.append(accur1_rf)\n",
    "    y_pred_proba = RF.predict_proba(X_test)\n",
    "    prec_rf=precision_score(y_test,pred_rf,average='macro')\n",
    "    rf_pre.append(prec_rf)\n",
    "    rec_rf=recall_score(y_test,pred_rf,average='macro')\n",
    "    rf_rec.append(rec_rf)\n",
    "    f1_rf=f1_score(y_test,pred_rf,average='macro')\n",
    "    rf_f1.append(f1_rf)\n",
    "    rf_confusion=confusion_matrix(y_test,pred_rf)\n",
    "    print(rf_confusion)\n",
    "    sensitivity = rf_confusion[0,0]/(rf_confusion[0,0]+rf_confusion[0,1])\n",
    "    ROC_score=roc_auc_score(y_test,y_pred_proba , average='weighted', multi_class='ovr')\n",
    "    lr_sen.append(sensitivity)\n",
    "    lr_roc.append(ROC_score)\n",
    "print('ROC_Score : ',np.mean (lr_roc))\n",
    "print('Sensitivity : ',np.mean (lr_sen))\n",
    "print('Scores for RF :',rf_score)\n",
    "print('Mean Test Score for RF:',np.mean(rf_score))\n",
    "print('Scores for RFt :',rft_score)\n",
    "print('Mean Training Score for RFt:',np.mean(rft_score))\n",
    "print('Precision Scores for RF :',rf_pre)\n",
    "print('Mean Precision Score for RF:',np.mean(rf_pre))\n",
    "print('Recall Scores for RF :',rf_rec)\n",
    "print('Mean Recall Score for RF:',np.mean(rf_rec))\n",
    "print('f1 Scores for RF :',rf_f1)\n",
    "print('Mean f1 Score for RF:',np.mean(rf_f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 1.0409908\ttotal: 323ms\tremaining: 1.94s\n",
      "1:\tlearn: 0.9879956\ttotal: 381ms\tremaining: 951ms\n",
      "2:\tlearn: 0.9382256\ttotal: 465ms\tremaining: 620ms\n",
      "3:\tlearn: 0.8940772\ttotal: 519ms\tremaining: 389ms\n",
      "4:\tlearn: 0.8522130\ttotal: 590ms\tremaining: 236ms\n",
      "5:\tlearn: 0.8141284\ttotal: 641ms\tremaining: 107ms\n",
      "6:\tlearn: 0.7776542\ttotal: 695ms\tremaining: 0us\n",
      "[[1249    0    0]\n",
      " [   0 1273   32]\n",
      " [   0    2 2429]]\n",
      "0:\tlearn: 1.0416015\ttotal: 64.3ms\tremaining: 386ms\n",
      "1:\tlearn: 0.9874412\ttotal: 125ms\tremaining: 313ms\n",
      "2:\tlearn: 0.9378371\ttotal: 186ms\tremaining: 248ms\n",
      "3:\tlearn: 0.8930689\ttotal: 253ms\tremaining: 190ms\n",
      "4:\tlearn: 0.8513938\ttotal: 316ms\tremaining: 127ms\n",
      "5:\tlearn: 0.8118291\ttotal: 379ms\tremaining: 63.2ms\n",
      "6:\tlearn: 0.7763808\ttotal: 437ms\tremaining: 0us\n",
      "[[1321    0    0]\n",
      " [   0 1307   19]\n",
      " [   0    0 2337]]\n",
      "0:\tlearn: 1.0409866\ttotal: 63.8ms\tremaining: 383ms\n",
      "1:\tlearn: 0.9869257\ttotal: 138ms\tremaining: 345ms\n",
      "2:\tlearn: 0.9375749\ttotal: 200ms\tremaining: 267ms\n",
      "3:\tlearn: 0.8928152\ttotal: 309ms\tremaining: 232ms\n",
      "4:\tlearn: 0.8512433\ttotal: 450ms\tremaining: 180ms\n",
      "5:\tlearn: 0.8127203\ttotal: 533ms\tremaining: 88.9ms\n",
      "6:\tlearn: 0.7769263\ttotal: 649ms\tremaining: 0us\n",
      "[[1304    5    0]\n",
      " [   0 1263   16]\n",
      " [   0    5 2391]]\n",
      "0:\tlearn: 1.0422982\ttotal: 71.1ms\tremaining: 426ms\n",
      "1:\tlearn: 0.9885658\ttotal: 126ms\tremaining: 316ms\n",
      "2:\tlearn: 0.9395239\ttotal: 184ms\tremaining: 245ms\n",
      "3:\tlearn: 0.8947176\ttotal: 236ms\tremaining: 177ms\n",
      "4:\tlearn: 0.8529758\ttotal: 288ms\tremaining: 115ms\n",
      "5:\tlearn: 0.8142197\ttotal: 339ms\tremaining: 56.5ms\n",
      "6:\tlearn: 0.7770657\ttotal: 397ms\tremaining: 0us\n",
      "[[1370    0    0]\n",
      " [   0 1267   19]\n",
      " [   0    0 2328]]\n",
      "ROC_Score :  0.999981207516533\n",
      "Sensitivity :  0.9990450725744844\n",
      "Scores for RF : [0.9931795386158475, 0.9961878009630819, 0.9947833065810594, 0.9961878009630819]\n",
      "Mean Test Score for RF: 0.9950846117807678\n",
      "Scores for RFt : [0.9953183520599251, 0.9963218083327761, 0.9933123787868655, 0.995920551059988]\n",
      "Mean Training Score for RFt: 0.9952182725598886\n",
      "Precision Scores for RF : [0.9951428427256044, 0.9973118279569894, 0.9951657538951211, 0.9973015196705014]\n",
      "Mean Precision Score for RF: 0.9962304860620541\n",
      "Recall Scores for RF : [0.9915520734993352, 0.9952237305178482, 0.9938612352284414, 0.9950751684810782]\n",
      "Mean Recall Score for RF: 0.9939280519316758\n",
      "f1 Scores for RF : [0.9932905275923778, 0.996245104566611, 0.9945087118388641, 0.9961645346811587]\n",
      "Mean f1 Score for RF: 0.9950522196697529\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(3)\n",
    "#CatBoost\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "RF=CatBoostClassifier(n_estimators=7,reg_lambda=0.1)\n",
    "rf_score  =[]\n",
    "rft_score=[]\n",
    "rf_pre=[]\n",
    "rf_rec=[]\n",
    "rf_f1=[]\n",
    "lr_sen=[]\n",
    "lr_roc=[]\n",
    "for train_index, test_index in kf.split(X):\n",
    "    X_train, y_train = X[train_index], y[train_index]\n",
    "    X_test, y_test   = X[test_index], y[test_index]\n",
    "    RF.fit(X_train,y_train)\n",
    "    pred_rf=RF.predict(X_test)\n",
    "    accur_rf=accuracy_score(y_test,pred_rf)\n",
    "    pred1_rf=RF.predict(X_train)\n",
    "    accur1_rf=accuracy_score(y_train,pred1_rf)\n",
    "    rf_score.append(accur_rf)\n",
    "    rft_score.append(accur1_rf)\n",
    "    y_pred_proba = RF.predict_proba(X_test)\n",
    "    prec_rf=precision_score(y_test,pred_rf,average='macro')\n",
    "    rf_pre.append(prec_rf)\n",
    "    rec_rf=recall_score(y_test,pred_rf,average='macro')\n",
    "    rf_rec.append(rec_rf)\n",
    "    f1_rf=f1_score(y_test,pred_rf,average='macro')\n",
    "    rf_f1.append(f1_rf)\n",
    "    rf_confusion=confusion_matrix(y_test,pred_rf)\n",
    "    print(rf_confusion)\n",
    "    sensitivity = rf_confusion[0,0]/(rf_confusion[0,0]+rf_confusion[0,1])\n",
    "    ROC_score=roc_auc_score(y_test,y_pred_proba , average='weighted', multi_class='ovr')\n",
    "    lr_sen.append(sensitivity)\n",
    "    lr_roc.append(ROC_score)\n",
    "print('ROC_Score : ',np.mean (lr_roc))\n",
    "print('Sensitivity : ',np.mean (lr_sen))\n",
    "print('Scores for RF :',rf_score)\n",
    "print('Mean Test Score for RF:',np.mean(rf_score))\n",
    "print('Scores for RFt :',rft_score)\n",
    "print('Mean Training Score for RFt:',np.mean(rft_score))\n",
    "print('Precision Scores for RF :',rf_pre)\n",
    "print('Mean Precision Score for RF:',np.mean(rf_pre))\n",
    "print('Recall Scores for RF :',rf_rec)\n",
    "print('Mean Recall Score for RF:',np.mean(rf_rec))\n",
    "print('f1 Scores for RF :',rf_f1)\n",
    "print('Mean f1 Score for RF:',np.mean(rf_f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "[[1328    5    0]\n",
      " [   0 1263    0]\n",
      " [   0   11 2378]]\n",
      "MLPClassifier(alpha=0.5, hidden_layer_sizes=800, random_state=1, tol=10)\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "[[1307    0    0]\n",
      " [   0 1346    0]\n",
      " [   0   12 2319]]\n",
      "MLPClassifier(alpha=3, hidden_layer_sizes=500, random_state=0, tol=0.001)\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "[[1324    1    0]\n",
      " [   0 1274    0]\n",
      " [   0   12 2373]]\n",
      "MLPClassifier(alpha=1, hidden_layer_sizes=500, random_state=1, tol=1)\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "[[1284    0    0]\n",
      " [   0 1313    0]\n",
      " [   0    1 2386]]\n",
      "MLPClassifier(alpha=0.1, hidden_layer_sizes=800, random_state=1, tol=0.001)\n",
      "ROC_Score :  0.999999499415401\n",
      "Sensitivity :  0.9988735863211086\n",
      "Scores for gb : [0.99679037111334, 0.9975922953451043, 0.9973916532905297, 0.9997993579454254]\n",
      "Mean Test Score for gb: 0.9978934194235998\n",
      "Scores for gbt : [0.997792937399679, 0.9979268374239283, 0.9979937136360596, 0.9993981140908179]\n",
      "Mean Training Score for gbt: 0.9982779006376212\n",
      "Precision Scores for gb : [0.9968305228429621, 0.9976135710857957, 0.9974180002269889, 0.9997995106410529]\n",
      "Mean Precision Score for gb: 0.9979154011991999\n",
      "Recall Scores for gb : [0.99679037111334, 0.9975922953451043, 0.9973916532905297, 0.9997993579454254]\n",
      "Mean Recall Score for gb: 0.9978934194235998\n",
      "f1 Scores for gb : [0.9967969839818651, 0.9975945311693353, 0.9973951993910134, 0.9997993751154209]\n",
      "Mean f1 Score for gb: 0.9978965224144086\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "#MLP\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "gb_score  =[]\n",
    "gbt_score=[]\n",
    "gb_pre=[]\n",
    "gb_rec=[]\n",
    "gb_f1=[]\n",
    "lr_sen=[]\n",
    "lr_roc=[]\n",
    "for train_index, test_index in kf.split(X,y):\n",
    "    X_train, y_train = X[train_index], y[train_index]\n",
    "    X_test, y_test   = X[test_index], y[test_index]\n",
    "    \n",
    "    parameters = {'hidden_layer_sizes': (10,100,300,500,800),'alpha': (0.0001,0.3,0.001,0.1,0.5,1,3,5),'random_state': (0,1),'tol': (0.0001,0.01\n",
    "                                                                                                                                     ,0.001,.1,1,10,50)}\n",
    "    DT_grid  = RandomizedSearchCV( MLPClassifier(), param_distributions = parameters, cv = 5, verbose = True,scoring='accuracy')\n",
    "    result=DT_grid.fit(X_train,y_train)\n",
    "    \n",
    "    gb = result.best_estimator_\n",
    "    pred_mlp = gb.predict(X_test)\n",
    "    y_pred_proba = gb.predict_proba(X_test) \n",
    "    pred1_gb=gb.predict(X_train)\n",
    "    accur_gb=accuracy_score(y_test,pred_mlp)\n",
    "    accur1_gb=accuracy_score(y_train,pred1_gb)\n",
    "    gb_score.append(accur_gb)\n",
    "    gbt_score.append(accur1_gb)\n",
    "    prec_gb=precision_score(y_test,pred_mlp,average='weighted')\n",
    "    gb_pre.append(prec_gb)\n",
    "    rec_gb=recall_score(y_test,pred_mlp,average='weighted')\n",
    "    gb_rec.append(rec_gb)\n",
    "    f1_gb=f1_score(y_test,pred_mlp,average='weighted')\n",
    "    gb_f1.append(f1_gb)\n",
    "    gb_confusion=confusion_matrix(y_test,pred_mlp)\n",
    "    print(gb_confusion)\n",
    "    sensitivity = gb_confusion[0,0]/(gb_confusion[0,0]+gb_confusion[0,1])\n",
    "    ROC_score=roc_auc_score(y_test,y_pred_proba , average='weighted', multi_class='ovr')\n",
    "    lr_sen.append(sensitivity)\n",
    "    lr_roc.append(ROC_score)\n",
    "    print(gb)\n",
    "print('ROC_Score : ',np.mean (lr_roc))\n",
    "print('Sensitivity : ',np.mean (lr_sen))\n",
    "print('Scores for gb :',gb_score)\n",
    "print('Mean Test Score for gb:',np.mean(gb_score))\n",
    "print('Scores for gbt :',gbt_score)\n",
    "print('Mean Training Score for gbt:',np.mean(gbt_score))\n",
    "print('Precision Scores for gb :',gb_pre)\n",
    "print('Mean Precision Score for gb:',np.mean(gb_pre))\n",
    "print('Recall Scores for gb :',gb_rec)\n",
    "print('Mean Recall Score for gb:',np.mean(gb_rec))\n",
    "print('f1 Scores for gb :',gb_f1)\n",
    "print('Mean f1 Score for gb:',np.mean(gb_f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "H:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:11:15] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[[1249    0    0]\n",
      " [   0 1305    0]\n",
      " [   0    0 2431]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "H:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:11:23] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[[1321    0    0]\n",
      " [   0 1326    0]\n",
      " [   0    0 2337]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "H:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:11:31] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[[1309    0    0]\n",
      " [   0 1279    0]\n",
      " [   0    0 2396]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "H:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:11:38] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[[1370    0    0]\n",
      " [   0 1286    0]\n",
      " [   0    0 2328]]\n",
      "ROC_Score :  1.0\n",
      "Sensitivity :  1.0\n",
      "Scores for RF : [1.0, 1.0, 1.0, 1.0]\n",
      "Mean Test Score for RF: 1.0\n",
      "Scores for RFt : [1.0, 1.0, 1.0, 1.0]\n",
      "Mean Training Score for RFt: 1.0\n",
      "Precision Scores for RF : [1.0, 1.0, 1.0, 1.0]\n",
      "Mean Precision Score for RF: 1.0\n",
      "Recall Scores for RF : [1.0, 1.0, 1.0, 1.0]\n",
      "Mean Recall Score for RF: 1.0\n",
      "f1 Scores for RF : [1.0, 1.0, 1.0, 1.0]\n",
      "Mean f1 Score for RF: 1.0\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(3)\n",
    "#xgbrf\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn=XGBRFClassifier(reg_lambda=0.5)\n",
    "rf_score  =[]\n",
    "rft_score=[]\n",
    "rf_pre=[]\n",
    "rf_rec=[]\n",
    "rf_f1=[]\n",
    "lr_sen=[]\n",
    "lr_roc=[]\n",
    "for train_index, test_index in kf.split(X):\n",
    "    X_train, y_train = X[train_index], y[train_index]\n",
    "    X_test, y_test   = X[test_index], y[test_index]\n",
    "    RF.fit(X_train,y_train)\n",
    "    pred_rf=RF.predict(X_test)\n",
    "    accur_rf=accuracy_score(y_test,pred_rf)\n",
    "    pred1_rf=RF.predict(X_train)\n",
    "    accur1_rf=accuracy_score(y_train,pred1_rf)\n",
    "    rf_score.append(accur_rf)\n",
    "    rft_score.append(accur1_rf)\n",
    "    y_pred_proba = RF.predict_proba(X_test)\n",
    "    prec_rf=precision_score(y_test,pred_rf,average='macro')\n",
    "    rf_pre.append(prec_rf)\n",
    "    rec_rf=recall_score(y_test,pred_rf,average='macro')\n",
    "    rf_rec.append(rec_rf)\n",
    "    f1_rf=f1_score(y_test,pred_rf,average='macro')\n",
    "    rf_f1.append(f1_rf)\n",
    "    rf_confusion=confusion_matrix(y_test,pred_rf)\n",
    "    print(rf_confusion)\n",
    "    sensitivity = rf_confusion[0,0]/(rf_confusion[0,0]+rf_confusion[0,1])\n",
    "    ROC_score=roc_auc_score(y_test,y_pred_proba , average='weighted', multi_class='ovr')\n",
    "    lr_sen.append(sensitivity)\n",
    "    lr_roc.append(ROC_score)\n",
    "print('ROC_Score : ',np.mean (lr_roc))\n",
    "print('Sensitivity : ',np.mean (lr_sen))\n",
    "print('Scores for RF :',rf_score)\n",
    "print('Mean Test Score for RF:',np.mean(rf_score))\n",
    "print('Scores for RFt :',rft_score)\n",
    "print('Mean Training Score for RFt:',np.mean(rft_score))\n",
    "print('Precision Scores for RF :',rf_pre)\n",
    "print('Mean Precision Score for RF:',np.mean(rf_pre))\n",
    "print('Recall Scores for RF :',rf_rec)\n",
    "print('Mean Recall Score for RF:',np.mean(rf_rec))\n",
    "print('f1 Scores for RF :',rf_f1)\n",
    "print('Mean f1 Score for RF:',np.mean(rf_f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
